# Workflow to update DynamoDB with policies from S3 after PR merge
name: Update Policies in DynamoDB

# Define workflow triggers
on:
  # Trigger on merged pull requests to dev or main branches
  pull_request:
    types: [closed]
    branches:
      - dev
      - main
  # Allow manual triggering with configurable inputs
  workflow_dispatch:
    inputs:
      # Environment for deployment (e.g., dev, prod)
      environment:
        description: "Environment to deploy"
        required: true
        type: string
        default: dev
      # Python version for AWS CLI
      python_version:
        description: Python version
        required: true
        type: string
        default: "3.11"
      # AWS region for resources
      aws_region:
        description: AWS region for deployment
        required: true
        type: string
        default: ap-southeast-2
      # S3 bucket name for policy files
      bucket_name:
        description: S3 bucket name for policy files
        required: true
        type: string
        default: guardrail-policy-deploy-temp
      # DynamoDB table name for policy storage
      table_name:
        description: DynamoDB table name
        required: true
        type: string
        default: prp-db-org-policy
      # Lambda function name to invoke
      lambda_function_name:
        description: Lambda function name
        required: true
        type: string
        default: GuardrailPolicyUpdate

# Define environment variables for the workflow
env:
  # AWS region, defaults to input or ap-southeast-2
  AWS_REGION: ${{ inputs.aws_region || 'ap-southeast-2' }}
  # S3 bucket name, defaults to input
  BUCKET_NAME: ${{ inputs.bucket_name || 'guardrail-policy-deploy-temp' }}
  # DynamoDB table name, defaults to input or prp-db-org-policy
  TABLE_NAME: ${{ inputs.table_name || 'prp-db-org-policy' }}
  # Lambda function name, defaults to input or GuardrailPolicyUpdate
  LAMBDA_FUNCTION_NAME: ${{ inputs.lambda_function_name || 'GuardrailPolicyUpdate' }}

# Define permissions for GitHub Actions
permissions:
  id-token: write # Allow writing to OIDC token for AWS authentication
  contents: write # Allow writing to repository contents
  actions: write  # Allow triggering other workflows (deploy-lambda.yml)

# Define jobs for the workflow
jobs:
  # Job to update policies in DynamoDB
  update-policies:
    runs-on: default # Use default runner
    # Only run if PR was merged
    if: github.event.pull_request.merged == true || github.event_name == 'workflow_dispatch'
    environment: ${{ inputs.environment || 'dev' }} # Set environment from input or default to dev

    steps:
      # Check out the repository code with full history
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch all history for accurate file checks

      # Debug the checkout to verify policy files
      - name: Debug checkout
        run: |
          echo "Current directory: $(pwd)"
          echo "Listing files in policies/:"
          ls -la policies/ || echo "No files found in policies/"
          if [ -f "policies/acm.json" ]; then
            echo "acm.json found, contents:"
            cat policies/acm.json
          else
            echo "acm.json not found in policies/"
          fi

      # Set up Python environment for AWS CLI
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python_version || '3.11' }}

      # Install Python dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -i https://artifactory.internal.cba/api/pypi/org.python.pypi/simple/ --upgrade awscli
        shell: bash

      # Configure AWS credentials using OIDC
      - name: Configure AWS credentials (AssumeRoleWithWebIdentity)
        uses: aws-actions/configure-aws-credentials@v2.2.0
        with:
          role-to-assume: ${{ secrets.GHA_TRUST_ROLE_ARN }} # Trusted role for GitHub Actions
          role-session-name: "GitHubActions"
          aws-region: ${{ env.AWS_REGION }}

      # Chain additional AWS role for CI/CD permissions
      - name: Configure AWS credentials (AssumeRole)
        uses: aws-actions/configure-aws-credentials@v2.2.0
        with:
          role-to-assume: ${{ secrets.GHA_CICD_ROLE_ARN }} # CI/CD role for deployment
          role-session-name: "GitHubActions"
          aws-region: ${{ env.AWS_REGION }}
          role-chaining: true

      # Check if the S3 bucket exists and clean it if present
      - name: Check if S3 Bucket Exists
        id: check-bucket
        run: |
          if aws s3api head-bucket --bucket ${{ env.BUCKET_NAME }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "Bucket ${{ env.BUCKET_NAME }} exists."
            echo "bucket_exists=true" >> $GITHUB_OUTPUT
            echo "Cleaning up existing objects in s3://${{ env.BUCKET_NAME }}/policies/..."
            aws s3 rm s3://${{ env.BUCKET_NAME }}/policies/ --recursive --region ${{ env.AWS_REGION }} || true
          else
            echo "Bucket ${{ env.BUCKET_NAME }} does not exist."
            echo "bucket_exists=false" >> $GITHUB_OUTPUT
          fi
        env:
          AWS_REGION: ${{ env.AWS_REGION }}

      # Trigger deploy-lambda.yml if bucket is missing
      - name: Trigger Deploy Lambda Workflow if Bucket Missing
        if: steps.check-bucket.outputs.bucket_exists == 'false'
        run: |
          curl -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/deploy-lambda.yml/dispatches \
            -d '{"ref":"main","inputs":{"environment":"${{ inputs.environment || 'dev' }}","python_version":"${{ inputs.python_version || '3.11' }}","aws_region":"${{ inputs.aws_region || 'ap-southeast-2' }}","bucket_name":"${{ inputs.bucket_name || 'grd-pol-123456789012' }}","stack_name":"guardrail-lambda-stack","table_name":"${{ inputs.table_name || 'prp-db-org-policy' }}","template_file":"guardrail-lambda.yml"}}'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Wait for bucket creation if it was missing
      - name: Wait for Bucket Creation
        if: steps.check-bucket.outputs.bucket_exists == 'false'
        run: |
          echo "Waiting for bucket ${{ env.BUCKET_NAME }} to be created..."
          for i in {1..30}; do
            if aws s3api head-bucket --bucket ${{ env.BUCKET_NAME }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
              echo "Bucket ${{ env.BUCKET_NAME }} created."
              exit 0
            fi
            echo "Bucket not yet available, waiting 10 seconds..."
            sleep 10
          done
          echo "Error: Bucket ${{ env.BUCKET_NAME }} was not created in time."
          exit 1
        env:
          AWS_REGION: ${{ env.AWS_REGION }}

      # Sync policy files to S3 bucket
      - name: Sync policies to S3
        run: |
          echo "Syncing policies/ to s3://${{ env.BUCKET_NAME }}/policies/"
          aws s3 sync policies/ s3://${{ env.BUCKET_NAME }}/policies/ --region ${{ env.AWS_REGION }} --debug
          echo "Listing S3 bucket contents after sync:"
          aws s3 ls s3://${{ env.BUCKET_NAME }}/policies/ --region ${{ env.AWS_REGION }} || echo "No files found in S3 bucket"
        env:
          AWS_REGION: ${{ env.AWS_REGION }}

      # Invoke Lambda to update DynamoDB
      - name: Invoke Lambda to update DynamoDB
        run: |
          echo "Invoking Lambda..."
          aws lambda invoke \
            --function-name ${{ env.LAMBDA_FUNCTION_NAME }} \
            --payload '{"table_name": "${{ env.TABLE_NAME }}", "bucket_name": "${{ env.BUCKET_NAME }}"}' \
            --region ${{ env.AWS_REGION }} \
            response.json
          if [ -f response.json ]; then
            echo "Lambda response:"
            cat response.json
          else
            echo "Error: response.json not generated"
            exit 1
          fi
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
